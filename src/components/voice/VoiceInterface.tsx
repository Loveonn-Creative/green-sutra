import React, { useState, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { useToast } from '@/components/ui/use-toast';
import { 
  Mic, 
  MicOff, 
  Volume2, 
  VolumeX, 
  Languages,
  Zap,
  Brain,
  Globe
} from 'lucide-react';
import LoadingSpinner from '@/components/ui/loading-spinner';

interface VoiceInterfaceProps {
  onLanguageChange?: (language: string) => void;
  currentLanguage?: string;
}

const VoiceInterface: React.FC<VoiceInterfaceProps> = ({ 
  onLanguageChange, 
  currentLanguage = 'en' 
}) => {
  const { toast } = useToast();
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState('');
  const [volume, setVolume] = useState(1);

  const supportedLanguages = [
    { code: 'en', name: 'English', flag: 'ðŸ‡ºðŸ‡¸' },
    { code: 'hi', name: 'à¤¹à¤¿à¤‚à¤¦à¥€', flag: 'ðŸ‡®ðŸ‡³' },
    { code: 'ta', name: 'à®¤à®®à®¿à®´à¯', flag: 'ðŸ‡®ðŸ‡³' },
    { code: 'bn', name: 'à¦¬à¦¾à¦‚à¦²à¦¾', flag: 'ðŸ‡§ðŸ‡©' },
    { code: 'te', name: 'à°¤à±†à°²à±à°—à±', flag: 'ðŸ‡®ðŸ‡³' },
    { code: 'bho', name: 'à¤­à¥‹à¤œà¤ªà¥à¤°à¥€', flag: 'ðŸ‡®ðŸ‡³' }
  ];

  const startListening = async () => {
    try {
      setIsListening(true);
      setTranscript('');
      
      // Mock voice recognition - in real implementation, would use Web Speech API or OpenAI
      setTimeout(() => {
        const mockTranscripts = {
          en: "Show me carbon tracking solutions for my business",
          hi: "à¤®à¥‡à¤°à¥‡ à¤µà¥à¤¯à¤µà¤¸à¤¾à¤¯ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤Ÿà¥à¤°à¥ˆà¤•à¤¿à¤‚à¤— à¤¸à¤®à¤¾à¤§à¤¾à¤¨ à¤¦à¤¿à¤–à¤¾à¤à¤‚",
          ta: "à®Žà®©à®¤à¯ à®µà®£à®¿à®•à®¤à¯à®¤à®¿à®±à¯à®•à®¾à®© à®•à®¾à®°à¯à®ªà®©à¯ à®•à®£à¯à®•à®¾à®£à®¿à®ªà¯à®ªà¯ à®¤à¯€à®°à¯à®µà¯à®•à®³à¯ˆà®•à¯ à®•à®¾à®Ÿà¯à®Ÿà¯",
          bn: "à¦†à¦®à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¸à¦¾à¦° à¦œà¦¨à§à¦¯ à¦•à¦¾à¦°à§à¦¬à¦¨ à¦Ÿà§à¦°à§à¦¯à¦¾à¦•à¦¿à¦‚ à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦¦à§‡à¦–à¦¾à¦¨",
          te: "à°¨à°¾ à°µà±à°¯à°¾à°ªà°¾à°°à°‚ à°•à±‹à°¸à°‚ à°•à°¾à°°à±à°¬à°¨à± à°Ÿà±à°°à°¾à°•à°¿à°‚à°—à± à°ªà°°à°¿à°·à±à°•à°¾à°°à°¾à°²à°¨à± à°šà±‚à°ªà°¿à°‚à°šà°‚à°¡à°¿",
          bho: "à¤¹à¤®à¤¾à¤° à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤° à¤–à¤¾à¤¤à¤¿à¤° à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤Ÿà¥à¤°à¥ˆà¤•à¤¿à¤‚à¤— à¤•à¥‡ à¤¸à¤®à¤¾à¤§à¤¾à¤¨ à¤¦à¥‡à¤–à¤¾à¤µs"
        };
        
        setTranscript(mockTranscripts[currentLanguage as keyof typeof mockTranscripts] || mockTranscripts.en);
        setIsListening(false);
        handleResponse();
      }, 2000);
      
    } catch (error) {
      setIsListening(false);
      toast({
        title: "Voice Error",
        description: "Could not access microphone. Please check permissions.",
        variant: "destructive"
      });
    }
  };

  const handleResponse = async () => {
    setIsSpeaking(true);
    
    // Mock AI response generation
    setTimeout(() => {
      const mockResponses = {
        en: "I can help you track carbon emissions for your MSME. Our Smart Carbon Ledger uses AI to monitor your energy consumption, fuel usage, and waste generation in real-time. Would you like me to show you the ESG evaluation page or carbon intelligence modules?",
        hi: "à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ MSME à¤•à¥‡ à¤²à¤¿à¤ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤‰à¤¤à¥à¤¸à¤°à¥à¤œà¤¨ à¤•à¥‹ à¤Ÿà¥à¤°à¥ˆà¤• à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤ à¤¹à¤®à¤¾à¤°à¤¾ à¤¸à¥à¤®à¤¾à¤°à¥à¤Ÿ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤²à¥‡à¤œà¤° AI à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤•à¥‡ à¤†à¤ªà¤•à¥€ à¤Šà¤°à¥à¤œà¤¾ à¤–à¤ªà¤¤, à¤ˆà¤‚à¤§à¤¨ à¤‰à¤ªà¤¯à¥‹à¤— à¤”à¤° à¤…à¤ªà¤¶à¤¿à¤·à¥à¤Ÿ à¤‰à¤¤à¥à¤ªà¤¾à¤¦à¤¨ à¤•à¥€ à¤°à¥€à¤¯à¤²-à¤Ÿà¤¾à¤‡à¤® à¤¨à¤¿à¤—à¤°à¤¾à¤¨à¥€ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆà¥¤",
        ta: "à®‰à®™à¯à®•à®³à¯ MSME à®•à¯à®•à®¾à®© à®•à®¾à®°à¯à®ªà®©à¯ à®‰à®®à®¿à®´à¯à®µà¯à®•à®³à¯ˆà®•à¯ à®•à®£à¯à®•à®¾à®£à®¿à®•à¯à®• à®¨à®¾à®©à¯ à®‰à®¤à®µ à®®à¯à®Ÿà®¿à®¯à¯à®®à¯. à®Žà®™à¯à®•à®³à¯ à®¸à¯à®®à®¾à®°à¯à®Ÿà¯ à®•à®¾à®°à¯à®ªà®©à¯ à®²à¯†à®Ÿà¯à®œà®°à¯ AI à®à®ªà¯ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤à®¿ à®‰à®™à¯à®•à®³à¯ à®†à®±à¯à®±à®²à¯ à®¨à¯à®•à®°à¯à®µà¯, à®Žà®°à®¿à®ªà¯Šà®°à¯à®³à¯ à®ªà®¯à®©à¯à®ªà®¾à®Ÿà¯ à®®à®±à¯à®±à¯à®®à¯ à®•à®´à®¿à®µà¯ à®‰à®±à¯à®ªà®¤à¯à®¤à®¿à®¯à¯ˆ à®¨à®¿à®•à®´à¯à®¨à¯‡à®°à®¤à¯à®¤à®¿à®²à¯ à®•à®£à¯à®•à®¾à®£à®¿à®•à¯à®•à®¿à®±à®¤à¯à¥¤",
        bn: "à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° MSME à¦à¦° à¦œà¦¨à§à¦¯ à¦•à¦¾à¦°à§à¦¬à¦¨ à¦¨à¦¿à¦°à§à¦—à¦®à¦¨ à¦Ÿà§à¦°à§à¦¯à¦¾à¦• à¦•à¦°à¦¤à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿à¥¤ à¦†à¦®à¦¾à¦¦à§‡à¦° à¦¸à§à¦®à¦¾à¦°à§à¦Ÿ à¦•à¦¾à¦°à§à¦¬à¦¨ à¦²à§‡à¦œà¦¾à¦° AI à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦†à¦ªà¦¨à¦¾à¦° à¦¶à¦•à§à¦¤à¦¿ à¦–à¦°à¦š, à¦œà§à¦¬à¦¾à¦²à¦¾à¦¨à¦¿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦à¦¬à¦‚ à¦¬à¦°à§à¦œà§à¦¯ à¦‰à§Žà¦ªà¦¾à¦¦à¦¨ à¦°à¦¿à¦¯à¦¼à§‡à¦²-à¦Ÿà¦¾à¦‡à¦®à§‡ à¦®à¦¨à¦¿à¦Ÿà¦° à¦•à¦°à§‡à¥¤",
        te: "à°®à±€ MSME à°•à±‹à°¸à°‚ à°•à°¾à°°à±à°¬à°¨à± à°‰à°¦à±à°—à°¾à°°à°¾à°²à°¨à± à°Ÿà±à°°à°¾à°•à± à°šà±‡à°¯à°¡à°‚à°²à±‹ à°¨à±‡à°¨à± à°¸à°¹à°¾à°¯à°‚ à°šà±‡à°¯à°—à°²à°¨à±à¥¤ à°®à°¾ à°¸à±à°®à°¾à°°à±à°Ÿà± à°•à°¾à°°à±à°¬à°¨à± à°²à±†à°¡à±à°œà°°à± AI à°¨à°¿ à°‰à°ªà°¯à±‹à°—à°¿à°‚à°šà°¿ à°®à±€ à°¶à°•à±à°¤à°¿ à°µà°¿à°¨à°¿à°¯à±‹à°—à°‚, à°‡à°‚à°§à°¨ à°µà°¿à°¨à°¿à°¯à±‹à°—à°‚ à°®à°°à°¿à°¯à± à°µà±à°¯à°°à±à°¥à°¾à°² à°‰à°¤à±à°ªà°¤à±à°¤à°¿à°¨à°¿ à°°à°¿à°¯à°²à± à°Ÿà±ˆà°®à±â€Œà°²à±‹ à°ªà°°à±à°¯à°µà±‡à°•à±à°·à°¿à°¸à±à°¤à±à°‚à°¦à°¿à¥¤",
        bho: "à¤¹à¤® à¤†à¤ªà¤•à¥‡ MSME à¤–à¤¾à¤¤à¤¿à¤° à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤‰à¤¤à¥à¤¸à¤°à¥à¤œà¤¨ à¤•à¥‡ à¤Ÿà¥à¤°à¥ˆà¤•à¤¿à¤‚à¤— à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤ à¤¬à¤¾à¤¨à¥€à¥¤ à¤¹à¤®à¤¾à¤° à¤¸à¥à¤®à¤¾à¤°à¥à¤Ÿ à¤•à¤¾à¤°à¥à¤¬à¤¨ à¤²à¥‡à¤œà¤° AI à¤•à¥‡ à¤‡à¤¸à¥à¤¤à¥‡à¤®à¤¾à¤² à¤¸à¥‡ à¤†à¤ªà¤•à¥‡ à¤Šà¤°à¥à¤œà¤¾ à¤–à¤ªà¤¤, à¤ˆà¤‚à¤§à¤¨ à¤•à¥‡ à¤‰à¤ªà¤¯à¥‹à¤— à¤† à¤•à¤šà¤°à¤¾ à¤•à¥‡ à¤‰à¤¤à¥à¤ªà¤¾à¤¦à¤¨ à¤•à¥‡ à¤°à¤¿à¤¯à¤²-à¤Ÿà¤¾à¤‡à¤® à¤¨à¤¿à¤—à¤°à¤¾à¤¨à¥€ à¤•à¤°à¥‡à¤²à¤¾à¥¤"
      };
      
      setResponse(mockResponses[currentLanguage as keyof typeof mockResponses] || mockResponses.en);
      setIsSpeaking(false);
      
      toast({
        title: "AI Response Ready",
        description: "Voice response generated in " + supportedLanguages.find(l => l.code === currentLanguage)?.name,
      });
    }, 3000);
  };

  const stopListening = () => {
    setIsListening(false);
  };

  const toggleMute = () => {
    setVolume(volume === 0 ? 1 : 0);
  };

  return (
    <div className="space-y-6">
      {/* Language Selection */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center space-x-2">
            <Languages className="h-5 w-5" />
            <span>Voice Language</span>
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="grid grid-cols-2 md:grid-cols-3 gap-3">
            {supportedLanguages.map((lang) => (
              <Button
                key={lang.code}
                variant={currentLanguage === lang.code ? "default" : "outline"}
                size="sm"
                onClick={() => onLanguageChange?.(lang.code)}
                className="flex items-center space-x-2"
              >
                <span className="text-lg">{lang.flag}</span>
                <span className="text-xs">{lang.name}</span>
              </Button>
            ))}
          </div>
          
          <div className="mt-4 p-3 bg-accent/20 rounded-lg">
            <p className="text-sm text-muted-foreground">
              <Globe className="h-4 w-4 inline mr-1" />
              Now supporting 6 Indian languages with AI-powered voice recognition
            </p>
          </div>
        </CardContent>
      </Card>

      {/* Voice Controls */}
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center space-x-2">
            <Brain className="h-5 w-5" />
            <span>AI Voice Assistant</span>
            <Badge variant="outline">
              {supportedLanguages.find(l => l.code === currentLanguage)?.name}
            </Badge>
          </CardTitle>
        </CardHeader>
        <CardContent className="space-y-6">
          {/* Main Voice Controls */}
          <div className="flex justify-center space-x-4">
            <Button
              size="lg"
              variant={isListening ? "destructive" : "default"}
              onClick={isListening ? stopListening : startListening}
              disabled={isSpeaking}
              className="h-16 w-16 rounded-full"
            >
              {isListening ? (
                <LoadingSpinner size="md" />
              ) : (
                <Mic className="h-6 w-6" />
              )}
            </Button>
            
            <Button
              size="lg"
              variant="outline"
              onClick={toggleMute}
              className="h-16 w-16 rounded-full"
            >
              {volume === 0 ? (
                <VolumeX className="h-6 w-6" />
              ) : (
                <Volume2 className="h-6 w-6" />
              )}
            </Button>
          </div>

          {/* Status Indicator */}
          <div className="text-center">
            {isListening && (
              <div className="flex items-center justify-center space-x-2 text-primary">
                <div className="animate-pulse">ðŸŽ¤</div>
                <span className="text-sm font-medium">Listening...</span>
              </div>
            )}
            
            {isSpeaking && (
              <div className="flex items-center justify-center space-x-2 text-success">
                <div className="animate-pulse">ðŸ”Š</div>
                <span className="text-sm font-medium">AI Responding...</span>
              </div>
            )}
            
            {!isListening && !isSpeaking && (
              <div className="text-muted-foreground">
                <Zap className="h-4 w-4 inline mr-1" />
                <span className="text-sm">Ready to help</span>
              </div>
            )}
          </div>

          {/* Voice Transcript */}
          {transcript && (
            <div className="p-4 bg-accent/30 rounded-lg">
              <h4 className="text-sm font-medium mb-2">You said:</h4>
              <p className="text-sm">{transcript}</p>
            </div>
          )}

          {/* AI Response */}
          {response && (
            <div className="p-4 bg-primary/5 border border-primary/20 rounded-lg">
              <h4 className="text-sm font-medium mb-2 text-primary">AI Assistant:</h4>
              <p className="text-sm">{response}</p>
            </div>
          )}

          {/* Quick Commands */}
          <div className="grid grid-cols-1 md:grid-cols-2 gap-3">
            <div className="p-3 bg-accent/20 rounded-lg">
              <h4 className="text-sm font-medium mb-2">Quick Commands:</h4>
              <ul className="text-xs text-muted-foreground space-y-1">
                <li>â€¢ "Show me carbon solutions"</li>
                <li>â€¢ "Navigate to ESG evaluation"</li>
                <li>â€¢ "Explain carbon tracking"</li>
                <li>â€¢ "Calculate my emissions"</li>
              </ul>
            </div>
            
            <div className="p-3 bg-accent/20 rounded-lg">
              <h4 className="text-sm font-medium mb-2">Available Pages:</h4>
              <ul className="text-xs text-muted-foreground space-y-1">
                <li>â€¢ Carbon Intelligence</li>
                <li>â€¢ ESG Evaluation</li>
                <li>â€¢ Voice Demo</li>
                <li>â€¢ Dashboard</li>
              </ul>
            </div>
          </div>
        </CardContent>
      </Card>
    </div>
  );
};

export default VoiceInterface;